{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrakharPatni08/Gen-AI/blob/main/NLP2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-Ng5dAkMecc"
      },
      "source": [
        "#Topic(NLP):-\n",
        "1. Tokeniztion\n",
        "2. Embeddings(Word2Vec, Glove)\n",
        "3. Bag-of-Words and TF-IDF\n",
        "4. Attention Mechanism\n",
        "5. Transformer Architecture\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TprmcUvBPNsZ"
      },
      "source": [
        "# Attention Mechanism:-\n",
        "Attention is a technique that allows a model to focus on specific words(in a sentence when performing a task)\n",
        "\n",
        "Why we need Attention??\n",
        "\n",
        "Attention lets the model attend to all parts of the sequence even for a part of word\n",
        "\n",
        "Type of Attention\n",
        "1. Self Attention\n",
        "2. Global Attention\n",
        "3. Local Attention\n",
        "4. Multi-head Attention(we generally use this by creating differents layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6evpumKLQ-2-"
      },
      "source": [
        "# Self Attention:-\n",
        "Q-\n",
        "\n",
        "K- What each word effect\n",
        "\n",
        "V-The word representaion\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwsfljBmX9uR",
        "outputId": "e72c5b6b-15f3-4f85-ca4c-6ace5cda9fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import imp libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as fn"
      ],
      "metadata": {
        "id": "uaRB445mYAh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"The\",\"Man\",\"Walk\"]\n",
        "\n",
        "e_d = 8"
      ],
      "metadata": {
        "id": "7xmdzbI4YJSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wor_to_idx = {i:index for index,i in enumerate(text)}\n",
        "print(wor_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQPV-nTlY0Zl",
        "outputId": "bfe9a106-5883-4154-c243-2ce4f87f98f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'The': 0, 'Man': 1, 'Walk': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_wor = torch.tensor([wor_to_idx[i] for i in text])\n",
        "print(idx_to_wor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye7vdmGWZE6L",
        "outputId": "43ec54f5-f52f-4094-be32-cbca63758f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Embeddings\n",
        "embedding = nn.Embedding(num_embeddings=len(wor_to_idx),embedding_dim=e_d)"
      ],
      "metadata": {
        "id": "9XrkdGzsapIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeded = embedding(idx_to_wor)"
      ],
      "metadata": {
        "id": "DSnFJ61CbJHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeded = embeded.unsqueeze(0)\n",
        "print(embeded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZts3D-4bkuh",
        "outputId": "30332b66-682d-43fc-8d90-f24a1092e471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-2.5539,  0.1809, -0.0506, -1.4260, -0.5434,  0.5640,  0.2569,\n",
            "           3.1843],\n",
            "         [-0.0187, -0.7345, -0.5684,  0.5810,  0.8992,  1.5609,  0.5232,\n",
            "          -0.1631],\n",
            "         [ 0.7423,  2.0302,  0.4327,  0.4340,  1.5537, -0.7219, -0.7162,\n",
            "           0.1250]]], grad_fn=<UnsqueezeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_head = 2\n",
        "multi_head = nn.MultiheadAttention(embed_dim=e_d,num_heads=num_head,batch_first=True)\n",
        "multi_head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMtVy52TcMKi",
        "outputId": "54bd55c6-e2e4-45ed-9101-4cafb6fc5033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiheadAttention(\n",
              "  (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_output, a_weights = multi_head(embeded,embeded,embeded)"
      ],
      "metadata": {
        "id": "j9bSNAOCc3fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1COaAd9ecXu",
        "outputId": "b9f49ad9-64b9-46d4-f460-271262cd450c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.2458, -0.2673, -0.4076, -0.1714, -0.0884, -0.2016,  0.2529,\n",
              "          -0.2823],\n",
              "         [-0.0067, -0.0585, -0.1169, -0.1029, -0.1953, -0.1630,  0.1746,\n",
              "           0.0253],\n",
              "         [-0.1679, -0.3407, -0.0121, -0.0587, -0.1625, -0.1971,  0.1999,\n",
              "           0.0492]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3nWkV7PedMU",
        "outputId": "31b8f49b-ccbc-42fb-a677-98db4c7e0dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.3669, 0.1968, 0.4363],\n",
              "         [0.2079, 0.3674, 0.4247],\n",
              "         [0.3303, 0.3317, 0.3380]]], grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_weights.squeeze(0).detach().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVw77tWhef1K",
        "outputId": "16190009-056b-488f-d808-90da01c6a1ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3668988 , 0.19678602, 0.43631512],\n",
              "       [0.20790541, 0.36741748, 0.42467713],\n",
              "       [0.33029765, 0.33169723, 0.33800516]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_weights"
      ],
      "metadata": {
        "id": "vGt_npuYfOSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVl1o3NCf2nV",
        "outputId": "d7ba5c33-1f83-413f-ba42-f9a3a4ed7b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import MarianTokenizer, MarianMTModel\n",
        "model = \"Helsinki-NLP/opus-mt-en-hi\"\n",
        "tok = MarianTokenizer.from_pretrained(model)\n",
        "models = MarianMTModel.from_pretrained(model)\n",
        "\n",
        "input_txt = [\"the man work\"]\n",
        "\n",
        "tok_input = tok(input_txt,return_tensors=\"pt\",padding=True,truncation=True)"
      ],
      "metadata": {
        "id": "hIpEcf5znHGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate = models.generate(**tok_input)"
      ],
      "metadata": {
        "id": "sAK4Ts1dnT66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHgVtFtHn2nE",
        "outputId": "363bd588-671c-4a1f-8904-4add7a0a1b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[61949,  1026,   182,   161,     5,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decode\n",
        "output = tok.batch_decode(translate,skip_special_tokens=True)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRiuocpBpx6Y",
        "outputId": "2d20fa5a-2451-4107-a3d8-b6cc20e619f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['आदमी काम करता है']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. numpy\n",
        "2. pandas\n",
        "3. matplotlib\n",
        "4. seaborn\n",
        "5. scipy\n",
        "6. sklearn\n",
        "\n",
        "7. pytorch\n",
        "8. tensorflow\n",
        "9. keras\n",
        "\n",
        "10. nltk\n",
        "11. transformers(huggingface)\n",
        "12. langDetect\n",
        "13. gensim\n",
        "14. OpenCV\n",
        "15. pillow\n",
        "16. torch vision\n",
        "17. fast ai(high level deep learning)\n",
        "\n",
        "CNN Task:-\n",
        "Face Mask detection usinng cnn and OpenCV"
      ],
      "metadata": {
        "id": "nClniO5qtjEh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTMlTlfhtl9_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1FXp4qBT/jqkIUNdvgXBX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}