{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPs0pKdLYlhOa+XQtfg0+6A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrakharPatni08/Gen-AI/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Backpropagation->\n",
        "Backpropagation is a learning algorithm that allow a neural network to learn by adjusting weights based on the error\n",
        "\n",
        "Steps:\n",
        "1. Forward pass(take the input, weight and bias calculate)\n"
      ],
      "metadata": {
        "id": "BcU-KYjKnDBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "uDsjSojNnOWp"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the iris data\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer,StandardScaler"
      ],
      "metadata": {
        "id": "MptIeFznrDsX"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66zmtOQ5rMYG",
        "outputId": "828094f4-2c39-4760-add0-9558222b2c02"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use LabelBinarizer\n",
        "data = LabelBinarizer()\n",
        "data1 = data.fit_transform(y)"
      ],
      "metadata": {
        "id": "ly675CaSrkZS"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize features\n",
        "scaler = StandardScaler()\n",
        "Scaled = scaler.fit_transform(x)"
      ],
      "metadata": {
        "id": "e9BDPGj2rXLL"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pST3kLVIrcLz",
        "outputId": "db5831ff-feab-461d-8722-55cebd733d93"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-9.00681170e-01  1.01900435e+00 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.14301691e+00 -1.31979479e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.38535265e+00  3.28414053e-01 -1.39706395e+00 -1.31544430e+00]\n",
            " [-1.50652052e+00  9.82172869e-02 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  1.24920112e+00 -1.34022653e+00 -1.31544430e+00]\n",
            " [-5.37177559e-01  1.93979142e+00 -1.16971425e+00 -1.05217993e+00]\n",
            " [-1.50652052e+00  7.88807586e-01 -1.34022653e+00 -1.18381211e+00]\n",
            " [-1.02184904e+00  7.88807586e-01 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.74885626e+00 -3.62176246e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.14301691e+00  9.82172869e-02 -1.28338910e+00 -1.44707648e+00]\n",
            " [-5.37177559e-01  1.47939788e+00 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.26418478e+00  7.88807586e-01 -1.22655167e+00 -1.31544430e+00]\n",
            " [-1.26418478e+00 -1.31979479e-01 -1.34022653e+00 -1.44707648e+00]\n",
            " [-1.87002413e+00 -1.31979479e-01 -1.51073881e+00 -1.44707648e+00]\n",
            " [-5.25060772e-02  2.16998818e+00 -1.45390138e+00 -1.31544430e+00]\n",
            " [-1.73673948e-01  3.09077525e+00 -1.28338910e+00 -1.05217993e+00]\n",
            " [-5.37177559e-01  1.93979142e+00 -1.39706395e+00 -1.05217993e+00]\n",
            " [-9.00681170e-01  1.01900435e+00 -1.34022653e+00 -1.18381211e+00]\n",
            " [-1.73673948e-01  1.70959465e+00 -1.16971425e+00 -1.18381211e+00]\n",
            " [-9.00681170e-01  1.70959465e+00 -1.28338910e+00 -1.18381211e+00]\n",
            " [-5.37177559e-01  7.88807586e-01 -1.16971425e+00 -1.31544430e+00]\n",
            " [-9.00681170e-01  1.47939788e+00 -1.28338910e+00 -1.05217993e+00]\n",
            " [-1.50652052e+00  1.24920112e+00 -1.56757623e+00 -1.31544430e+00]\n",
            " [-9.00681170e-01  5.58610819e-01 -1.16971425e+00 -9.20547742e-01]\n",
            " [-1.26418478e+00  7.88807586e-01 -1.05603939e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00 -1.31979479e-01 -1.22655167e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  7.88807586e-01 -1.22655167e+00 -1.05217993e+00]\n",
            " [-7.79513300e-01  1.01900435e+00 -1.28338910e+00 -1.31544430e+00]\n",
            " [-7.79513300e-01  7.88807586e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.38535265e+00  3.28414053e-01 -1.22655167e+00 -1.31544430e+00]\n",
            " [-1.26418478e+00  9.82172869e-02 -1.22655167e+00 -1.31544430e+00]\n",
            " [-5.37177559e-01  7.88807586e-01 -1.28338910e+00 -1.05217993e+00]\n",
            " [-7.79513300e-01  2.40018495e+00 -1.28338910e+00 -1.44707648e+00]\n",
            " [-4.16009689e-01  2.63038172e+00 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.14301691e+00  9.82172869e-02 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  3.28414053e-01 -1.45390138e+00 -1.31544430e+00]\n",
            " [-4.16009689e-01  1.01900435e+00 -1.39706395e+00 -1.31544430e+00]\n",
            " [-1.14301691e+00  1.24920112e+00 -1.34022653e+00 -1.44707648e+00]\n",
            " [-1.74885626e+00 -1.31979479e-01 -1.39706395e+00 -1.31544430e+00]\n",
            " [-9.00681170e-01  7.88807586e-01 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  1.01900435e+00 -1.39706395e+00 -1.18381211e+00]\n",
            " [-1.62768839e+00 -1.74335684e+00 -1.39706395e+00 -1.18381211e+00]\n",
            " [-1.74885626e+00  3.28414053e-01 -1.39706395e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  1.01900435e+00 -1.22655167e+00 -7.88915558e-01]\n",
            " [-9.00681170e-01  1.70959465e+00 -1.05603939e+00 -1.05217993e+00]\n",
            " [-1.26418478e+00 -1.31979479e-01 -1.34022653e+00 -1.18381211e+00]\n",
            " [-9.00681170e-01  1.70959465e+00 -1.22655167e+00 -1.31544430e+00]\n",
            " [-1.50652052e+00  3.28414053e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [-6.58345429e-01  1.47939788e+00 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  5.58610819e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [ 1.40150837e+00  3.28414053e-01  5.35408562e-01  2.64141916e-01]\n",
            " [ 6.74501145e-01  3.28414053e-01  4.21733708e-01  3.95774101e-01]\n",
            " [ 1.28034050e+00  9.82172869e-02  6.49083415e-01  3.95774101e-01]\n",
            " [-4.16009689e-01 -1.74335684e+00  1.37546573e-01  1.32509732e-01]\n",
            " [ 7.95669016e-01 -5.92373012e-01  4.78571135e-01  3.95774101e-01]\n",
            " [-1.73673948e-01 -5.92373012e-01  4.21733708e-01  1.32509732e-01]\n",
            " [ 5.53333275e-01  5.58610819e-01  5.35408562e-01  5.27406285e-01]\n",
            " [-1.14301691e+00 -1.51316008e+00 -2.60315415e-01 -2.62386821e-01]\n",
            " [ 9.16836886e-01 -3.62176246e-01  4.78571135e-01  1.32509732e-01]\n",
            " [-7.79513300e-01 -8.22569778e-01  8.07091462e-02  2.64141916e-01]\n",
            " [-1.02184904e+00 -2.43394714e+00 -1.46640561e-01 -2.62386821e-01]\n",
            " [ 6.86617933e-02 -1.31979479e-01  2.51221427e-01  3.95774101e-01]\n",
            " [ 1.89829664e-01 -1.97355361e+00  1.37546573e-01 -2.62386821e-01]\n",
            " [ 3.10997534e-01 -3.62176246e-01  5.35408562e-01  2.64141916e-01]\n",
            " [-2.94841818e-01 -3.62176246e-01 -8.98031345e-02  1.32509732e-01]\n",
            " [ 1.03800476e+00  9.82172869e-02  3.64896281e-01  2.64141916e-01]\n",
            " [-2.94841818e-01 -1.31979479e-01  4.21733708e-01  3.95774101e-01]\n",
            " [-5.25060772e-02 -8.22569778e-01  1.94384000e-01 -2.62386821e-01]\n",
            " [ 4.32165405e-01 -1.97355361e+00  4.21733708e-01  3.95774101e-01]\n",
            " [-2.94841818e-01 -1.28296331e+00  8.07091462e-02 -1.30754636e-01]\n",
            " [ 6.86617933e-02  3.28414053e-01  5.92245988e-01  7.90670654e-01]\n",
            " [ 3.10997534e-01 -5.92373012e-01  1.37546573e-01  1.32509732e-01]\n",
            " [ 5.53333275e-01 -1.28296331e+00  6.49083415e-01  3.95774101e-01]\n",
            " [ 3.10997534e-01 -5.92373012e-01  5.35408562e-01  8.77547895e-04]\n",
            " [ 6.74501145e-01 -3.62176246e-01  3.08058854e-01  1.32509732e-01]\n",
            " [ 9.16836886e-01 -1.31979479e-01  3.64896281e-01  2.64141916e-01]\n",
            " [ 1.15917263e+00 -5.92373012e-01  5.92245988e-01  2.64141916e-01]\n",
            " [ 1.03800476e+00 -1.31979479e-01  7.05920842e-01  6.59038469e-01]\n",
            " [ 1.89829664e-01 -3.62176246e-01  4.21733708e-01  3.95774101e-01]\n",
            " [-1.73673948e-01 -1.05276654e+00 -1.46640561e-01 -2.62386821e-01]\n",
            " [-4.16009689e-01 -1.51316008e+00  2.38717193e-02 -1.30754636e-01]\n",
            " [-4.16009689e-01 -1.51316008e+00 -3.29657076e-02 -2.62386821e-01]\n",
            " [-5.25060772e-02 -8.22569778e-01  8.07091462e-02  8.77547895e-04]\n",
            " [ 1.89829664e-01 -8.22569778e-01  7.62758269e-01  5.27406285e-01]\n",
            " [-5.37177559e-01 -1.31979479e-01  4.21733708e-01  3.95774101e-01]\n",
            " [ 1.89829664e-01  7.88807586e-01  4.21733708e-01  5.27406285e-01]\n",
            " [ 1.03800476e+00  9.82172869e-02  5.35408562e-01  3.95774101e-01]\n",
            " [ 5.53333275e-01 -1.74335684e+00  3.64896281e-01  1.32509732e-01]\n",
            " [-2.94841818e-01 -1.31979479e-01  1.94384000e-01  1.32509732e-01]\n",
            " [-4.16009689e-01 -1.28296331e+00  1.37546573e-01  1.32509732e-01]\n",
            " [-4.16009689e-01 -1.05276654e+00  3.64896281e-01  8.77547895e-04]\n",
            " [ 3.10997534e-01 -1.31979479e-01  4.78571135e-01  2.64141916e-01]\n",
            " [-5.25060772e-02 -1.05276654e+00  1.37546573e-01  8.77547895e-04]\n",
            " [-1.02184904e+00 -1.74335684e+00 -2.60315415e-01 -2.62386821e-01]\n",
            " [-2.94841818e-01 -8.22569778e-01  2.51221427e-01  1.32509732e-01]\n",
            " [-1.73673948e-01 -1.31979479e-01  2.51221427e-01  8.77547895e-04]\n",
            " [-1.73673948e-01 -3.62176246e-01  2.51221427e-01  1.32509732e-01]\n",
            " [ 4.32165405e-01 -3.62176246e-01  3.08058854e-01  1.32509732e-01]\n",
            " [-9.00681170e-01 -1.28296331e+00 -4.30827696e-01 -1.30754636e-01]\n",
            " [-1.73673948e-01 -5.92373012e-01  1.94384000e-01  1.32509732e-01]\n",
            " [ 5.53333275e-01  5.58610819e-01  1.27429511e+00  1.71209594e+00]\n",
            " [-5.25060772e-02 -8.22569778e-01  7.62758269e-01  9.22302838e-01]\n",
            " [ 1.52267624e+00 -1.31979479e-01  1.21745768e+00  1.18556721e+00]\n",
            " [ 5.53333275e-01 -3.62176246e-01  1.04694540e+00  7.90670654e-01]\n",
            " [ 7.95669016e-01 -1.31979479e-01  1.16062026e+00  1.31719939e+00]\n",
            " [ 2.12851559e+00 -1.31979479e-01  1.61531967e+00  1.18556721e+00]\n",
            " [-1.14301691e+00 -1.28296331e+00  4.21733708e-01  6.59038469e-01]\n",
            " [ 1.76501198e+00 -3.62176246e-01  1.44480739e+00  7.90670654e-01]\n",
            " [ 1.03800476e+00 -1.28296331e+00  1.16062026e+00  7.90670654e-01]\n",
            " [ 1.64384411e+00  1.24920112e+00  1.33113254e+00  1.71209594e+00]\n",
            " [ 7.95669016e-01  3.28414053e-01  7.62758269e-01  1.05393502e+00]\n",
            " [ 6.74501145e-01 -8.22569778e-01  8.76433123e-01  9.22302838e-01]\n",
            " [ 1.15917263e+00 -1.31979479e-01  9.90107977e-01  1.18556721e+00]\n",
            " [-1.73673948e-01 -1.28296331e+00  7.05920842e-01  1.05393502e+00]\n",
            " [-5.25060772e-02 -5.92373012e-01  7.62758269e-01  1.58046376e+00]\n",
            " [ 6.74501145e-01  3.28414053e-01  8.76433123e-01  1.44883158e+00]\n",
            " [ 7.95669016e-01 -1.31979479e-01  9.90107977e-01  7.90670654e-01]\n",
            " [ 2.24968346e+00  1.70959465e+00  1.67215710e+00  1.31719939e+00]\n",
            " [ 2.24968346e+00 -1.05276654e+00  1.78583195e+00  1.44883158e+00]\n",
            " [ 1.89829664e-01 -1.97355361e+00  7.05920842e-01  3.95774101e-01]\n",
            " [ 1.28034050e+00  3.28414053e-01  1.10378283e+00  1.44883158e+00]\n",
            " [-2.94841818e-01 -5.92373012e-01  6.49083415e-01  1.05393502e+00]\n",
            " [ 2.24968346e+00 -5.92373012e-01  1.67215710e+00  1.05393502e+00]\n",
            " [ 5.53333275e-01 -8.22569778e-01  6.49083415e-01  7.90670654e-01]\n",
            " [ 1.03800476e+00  5.58610819e-01  1.10378283e+00  1.18556721e+00]\n",
            " [ 1.64384411e+00  3.28414053e-01  1.27429511e+00  7.90670654e-01]\n",
            " [ 4.32165405e-01 -5.92373012e-01  5.92245988e-01  7.90670654e-01]\n",
            " [ 3.10997534e-01 -1.31979479e-01  6.49083415e-01  7.90670654e-01]\n",
            " [ 6.74501145e-01 -5.92373012e-01  1.04694540e+00  1.18556721e+00]\n",
            " [ 1.64384411e+00 -1.31979479e-01  1.16062026e+00  5.27406285e-01]\n",
            " [ 1.88617985e+00 -5.92373012e-01  1.33113254e+00  9.22302838e-01]\n",
            " [ 2.49201920e+00  1.70959465e+00  1.50164482e+00  1.05393502e+00]\n",
            " [ 6.74501145e-01 -5.92373012e-01  1.04694540e+00  1.31719939e+00]\n",
            " [ 5.53333275e-01 -5.92373012e-01  7.62758269e-01  3.95774101e-01]\n",
            " [ 3.10997534e-01 -1.05276654e+00  1.04694540e+00  2.64141916e-01]\n",
            " [ 2.24968346e+00 -1.31979479e-01  1.33113254e+00  1.44883158e+00]\n",
            " [ 5.53333275e-01  7.88807586e-01  1.04694540e+00  1.58046376e+00]\n",
            " [ 6.74501145e-01  9.82172869e-02  9.90107977e-01  7.90670654e-01]\n",
            " [ 1.89829664e-01 -1.31979479e-01  5.92245988e-01  7.90670654e-01]\n",
            " [ 1.28034050e+00  9.82172869e-02  9.33270550e-01  1.18556721e+00]\n",
            " [ 1.03800476e+00  9.82172869e-02  1.04694540e+00  1.58046376e+00]\n",
            " [ 1.28034050e+00  9.82172869e-02  7.62758269e-01  1.44883158e+00]\n",
            " [-5.25060772e-02 -8.22569778e-01  7.62758269e-01  9.22302838e-01]\n",
            " [ 1.15917263e+00  3.28414053e-01  1.21745768e+00  1.44883158e+00]\n",
            " [ 1.03800476e+00  5.58610819e-01  1.10378283e+00  1.71209594e+00]\n",
            " [ 1.03800476e+00 -1.31979479e-01  8.19595696e-01  1.44883158e+00]\n",
            " [ 5.53333275e-01 -1.28296331e+00  7.05920842e-01  9.22302838e-01]\n",
            " [ 7.95669016e-01 -1.31979479e-01  8.19595696e-01  1.05393502e+00]\n",
            " [ 4.32165405e-01  7.88807586e-01  9.33270550e-01  1.44883158e+00]\n",
            " [ 6.86617933e-02 -1.31979479e-01  7.62758269e-01  7.90670654e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(Scaled,data1,test_size = 0.2)"
      ],
      "metadata": {
        "id": "8HaviQmPruJy"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZkSD68Br5oq",
        "outputId": "e75eaffd-3d4f-42c5-93af-e13da8e5658e"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GQuQJf6sPyN",
        "outputId": "31fee783-4ef3-4fe7-a2bf-c5521f2d8b40"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Deep Learning Model(Without Backpropagation)\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras import regularizers\n",
        "def model_creation():\n",
        "  model = Sequential([\n",
        "      Dense(10,input_shape=(4,),activation='relu',kernel_regularizer=regulizers.l1(0.01)),\n",
        "      Dense(3,activation='softmax'),\n",
        "    ])\n",
        "  model.compile(optimizer=SGD(learning_rate=0.1),loss=(\"CategoricalCrossentropy\"),metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "R0HaveK05oLV"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1= model_creation()\n",
        "pred1 = model1.predict(x_test)\n",
        "print(pred1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bxYiH1guISI",
        "outputId": "13cc71f6-9586-4e49-d481-9861286e063d"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "[[0.52480763 0.1554839  0.3197085 ]\n",
            " [0.3362208  0.17967905 0.48410013]\n",
            " [0.42860222 0.27554655 0.29585117]\n",
            " [0.36542425 0.32134143 0.31323436]\n",
            " [0.4953004  0.14883228 0.3558673 ]\n",
            " [0.4188587  0.2571178  0.32402351]\n",
            " [0.38661602 0.4260955  0.18728839]\n",
            " [0.38304392 0.18550254 0.43145362]\n",
            " [0.38895905 0.33007973 0.2809613 ]\n",
            " [0.34751067 0.4861133  0.16637605]\n",
            " [0.3868047  0.46687716 0.14631814]\n",
            " [0.3334453  0.37063792 0.29591674]\n",
            " [0.25830022 0.59713167 0.14456812]\n",
            " [0.25562876 0.6384422  0.10592892]\n",
            " [0.31731415 0.40802294 0.2746629 ]\n",
            " [0.32018885 0.14745276 0.5323584 ]\n",
            " [0.34473744 0.43389004 0.2213724 ]\n",
            " [0.6409093  0.14831613 0.21077451]\n",
            " [0.36213297 0.43872535 0.19914168]\n",
            " [0.32222876 0.1428398  0.5349314 ]\n",
            " [0.40289932 0.17637877 0.42072195]\n",
            " [0.32429567 0.14128365 0.5344208 ]\n",
            " [0.37099823 0.5240652  0.10493644]\n",
            " [0.40330887 0.30245727 0.2942338 ]\n",
            " [0.41488189 0.2888633  0.2962548 ]\n",
            " [0.33307785 0.13838972 0.52853245]\n",
            " [0.28624645 0.12700658 0.58674693]\n",
            " [0.39665446 0.14157428 0.46177122]\n",
            " [0.504541   0.15287589 0.3425831 ]\n",
            " [0.5913361  0.16325337 0.24541053]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model with backpropagation\n",
        "model2 = model_creation()\n",
        "model2.fit(x_train,y_train,epochs=100)\n",
        "pred2 = model2.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QUwRtv4xTPo",
        "outputId": "6b768b92-02aa-4195-f293-383fa0e0d367"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3433 - loss: 1.1876 \n",
            "Epoch 2/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6298 - loss: 0.8667\n",
            "Epoch 3/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6679 - loss: 0.7269\n",
            "Epoch 4/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7142 - loss: 0.6909 \n",
            "Epoch 5/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7542 - loss: 0.6011\n",
            "Epoch 6/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7481 - loss: 0.5718 \n",
            "Epoch 7/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7600 - loss: 0.5462\n",
            "Epoch 8/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7967 - loss: 0.4894 \n",
            "Epoch 9/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7792 - loss: 0.4922 \n",
            "Epoch 10/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8044 - loss: 0.4549 \n",
            "Epoch 11/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8148 - loss: 0.4285 \n",
            "Epoch 12/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8231 - loss: 0.4161\n",
            "Epoch 13/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7965 - loss: 0.4497 \n",
            "Epoch 14/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8246 - loss: 0.3970\n",
            "Epoch 15/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8185 - loss: 0.3954  \n",
            "Epoch 16/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8248 - loss: 0.3804\n",
            "Epoch 17/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8365 - loss: 0.3624\n",
            "Epoch 18/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8531 - loss: 0.3483\n",
            "Epoch 19/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8671 - loss: 0.3204\n",
            "Epoch 20/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8754 - loss: 0.3205\n",
            "Epoch 21/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8413 - loss: 0.3763\n",
            "Epoch 22/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8163 - loss: 0.3688 \n",
            "Epoch 23/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8790 - loss: 0.3172 \n",
            "Epoch 24/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8685 - loss: 0.3186\n",
            "Epoch 25/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8727 - loss: 0.3117\n",
            "Epoch 26/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8708 - loss: 0.3141 \n",
            "Epoch 27/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8698 - loss: 0.3221 \n",
            "Epoch 28/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8771 - loss: 0.3267 \n",
            "Epoch 29/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8867 - loss: 0.2843 \n",
            "Epoch 30/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8973 - loss: 0.2888\n",
            "Epoch 31/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9067 - loss: 0.2700\n",
            "Epoch 32/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8775 - loss: 0.2950\n",
            "Epoch 33/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8892 - loss: 0.2811\n",
            "Epoch 34/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9038 - loss: 0.2526\n",
            "Epoch 35/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9073 - loss: 0.2719 \n",
            "Epoch 36/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9221 - loss: 0.2471\n",
            "Epoch 37/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9354 - loss: 0.2286 \n",
            "Epoch 38/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9115 - loss: 0.2317 \n",
            "Epoch 39/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9096 - loss: 0.2535 \n",
            "Epoch 40/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9252 - loss: 0.2426 \n",
            "Epoch 41/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9421 - loss: 0.2105\n",
            "Epoch 42/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9377 - loss: 0.2073\n",
            "Epoch 43/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9392 - loss: 0.2222\n",
            "Epoch 44/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9340 - loss: 0.2253\n",
            "Epoch 45/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9454 - loss: 0.2096\n",
            "Epoch 46/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9485 - loss: 0.1949\n",
            "Epoch 47/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9569 - loss: 0.1830 \n",
            "Epoch 48/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9423 - loss: 0.1840 \n",
            "Epoch 49/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9413 - loss: 0.1858 \n",
            "Epoch 50/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9498 - loss: 0.1835\n",
            "Epoch 51/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9560 - loss: 0.1679\n",
            "Epoch 52/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9300 - loss: 0.1985 \n",
            "Epoch 53/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9394 - loss: 0.1714\n",
            "Epoch 54/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9623 - loss: 0.1530 \n",
            "Epoch 55/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9529 - loss: 0.1465\n",
            "Epoch 56/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9446 - loss: 0.1567 \n",
            "Epoch 57/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9706 - loss: 0.1352\n",
            "Epoch 58/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9719 - loss: 0.1362 \n",
            "Epoch 59/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9721 - loss: 0.1620 \n",
            "Epoch 60/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9721 - loss: 0.1380 \n",
            "Epoch 61/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9625 - loss: 0.1311\n",
            "Epoch 62/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9585 - loss: 0.1542 \n",
            "Epoch 63/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9502 - loss: 0.1580 \n",
            "Epoch 64/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9638 - loss: 0.1480 \n",
            "Epoch 65/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9658 - loss: 0.1363\n",
            "Epoch 66/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9742 - loss: 0.1177 \n",
            "Epoch 67/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9523 - loss: 0.1434\n",
            "Epoch 68/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9794 - loss: 0.1203\n",
            "Epoch 69/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9565 - loss: 0.1332 \n",
            "Epoch 70/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9523 - loss: 0.1368 \n",
            "Epoch 71/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9523 - loss: 0.1342\n",
            "Epoch 72/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9679 - loss: 0.1225\n",
            "Epoch 73/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9700 - loss: 0.1129\n",
            "Epoch 74/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9648 - loss: 0.1156 \n",
            "Epoch 75/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9806 - loss: 0.1180 \n",
            "Epoch 76/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9773 - loss: 0.1034\n",
            "Epoch 77/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9627 - loss: 0.1226 \n",
            "Epoch 78/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9627 - loss: 0.1175 \n",
            "Epoch 79/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9733 - loss: 0.1125\n",
            "Epoch 80/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9744 - loss: 0.1047\n",
            "Epoch 81/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9765 - loss: 0.1016 \n",
            "Epoch 82/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9721 - loss: 0.0962 \n",
            "Epoch 83/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9796 - loss: 0.1044\n",
            "Epoch 84/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9765 - loss: 0.1007\n",
            "Epoch 85/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9827 - loss: 0.0993\n",
            "Epoch 86/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9806 - loss: 0.0829 \n",
            "Epoch 87/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9712 - loss: 0.0898\n",
            "Epoch 88/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9681 - loss: 0.0977 \n",
            "Epoch 89/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9796 - loss: 0.0821 \n",
            "Epoch 90/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9744 - loss: 0.0962 \n",
            "Epoch 91/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9765 - loss: 0.0891\n",
            "Epoch 92/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9858 - loss: 0.0750\n",
            "Epoch 93/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9765 - loss: 0.0776\n",
            "Epoch 94/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9744 - loss: 0.0925 \n",
            "Epoch 95/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9744 - loss: 0.0861 \n",
            "Epoch 96/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9806 - loss: 0.0814\n",
            "Epoch 97/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9827 - loss: 0.0834 \n",
            "Epoch 98/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9775 - loss: 0.0881 \n",
            "Epoch 99/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9744 - loss: 0.0877 \n",
            "Epoch 100/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9712 - loss: 0.0862 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#With Backpropagation\n",
        "loss,acc = model2.evaluate(x_test,y_test)\n",
        "print(\"Accuracy is--> \",acc,\"Loss is -->\",loss)\n",
        "#Without Backpropagation\n",
        "loss1,acc1 = model1.evaluate(x_test,y_test)\n",
        "print(\"Accuracy is--> \",acc1,\"Loss is --> \",loss1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soQSzuznxGbj",
        "outputId": "4a5f0f96-a796-467b-e01a-ca6a5ee4c75a"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9667 - loss: 0.0893\n",
            "Accuracy is-->  0.9666666388511658 Loss is --> 0.08926929533481598\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2333 - loss: 1.2125\n",
            "Accuracy is-->  0.23333333432674408 Loss is -->  1.2125492095947266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imp Questions and points\n",
        "1. What is Deep learning?\n",
        "2. Regularization adds a loss penalty to the model to prevent the model from being overfitten or from being complex\n",
        "3. what is filter in cnn?\n",
        "4. what is LSTM?\n",
        "5. What is optimizer, backpropagation, regularization and its techniques?\n",
        "6. what is overfitting, and how to avoid it?\n",
        "7. what is underfitting, and how to avoid it?\n",
        "8. what is neurons?\n",
        "9. what is flatten ,dense layer?\n",
        "10. what is activation fuction and what is relu ,tanh,softmax,sigmoid?\n",
        "11. what is CNN ? how we can import and resuse\n",
        "12. What is dropout? how we can use dropout?\n",
        "13. What is pixel(10,20-28,784)?\n",
        "14. Why do we need backpropagation in optimizer?\n",
        "15. deep learning layers (feed forward)"
      ],
      "metadata": {
        "id": "KhdxOEE713Kv"
      }
    }
  ]
}